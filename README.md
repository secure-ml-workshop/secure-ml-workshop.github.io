# Workshop on Dataset Curation and Security - NeurIPS 2020, December 11th

Classical machine learning research has been focused largely on models,  optimizers,  and computational challenges. As technical progress and hardware advancements ease these challenges, practitioners are now finding that the limitations and faults of their models are the result of their datasets. This is particularly true of deep networks, which often rely on huge datasets that are too large and unwieldy for domain experts to curate by hand. We invite those interested to contribute in the discussion around dataset curation and security.

We have identified four areas of interest: Dataset security, policy and privacy, dataset bias, and data scraping and labeling. In addition to the invited speakers listed below, we are excited to invite paper submissions on the topics of data poisoning and backdoor attacks, data sanitization, dataset bias, and dataset privacy. Broadly, this workshop is about data, so if your work is on datasets, their curation and impact, then this workshop is for you! See the [call for papers](#cfp) below for more details. If you have any questions, please reach out to Micah Goldblum (<goldblumcello@gmail.com>).

## Invited Speakers

**[Aleksander Mądry](https://people.csail.mit.edu/madry/),** _MIT_.

**[Darrell M. West](https://www.brookings.edu/experts/darrell-m-west/),** _Brookings Institution_.

**[Dawn Song](https://people.eecs.berkeley.edu/~dawnsong/?_ga=2.130447496.627426393.1600173880-497787535.1600173880),** _UC Berkeley_.

**[Liz O'Sullivan](https://www.lizjosullivan.com/),** 
_Liz O’Sullivan co-founded Arthur AI, an AI monitoring and explainability company, where she serves as Vice President of Commercial Operations. She has been working in the AI space since 2012, delivering large-scale AI projects across industries to Fortune 500 clients. Most recently, she headed data labeling at computer vision AI startup Clarifai, which is where she first held responsibility for reducing model bias through a well-managed annotations pipeline. Liz also acts as Technology Director for STOP (the Surveillance Technology Oversight Project) where she works on New York City and State policy to protect personal privacy from the ever-growing surveillance state. She has been an active voice in the AI ethics movement, and has been featured in numerous media outlets discussing data privacy and ethical AI. Liz is an active member of the Campaign to Stop Killer Robots and advocates on their behalf to US legislative bodies, federal agencies, and at the UN._

**[Rob Nowak](https://nowak.ece.wisc.edu/),** 
_Robert Nowak holds the Nosbusch Professorship in Engineering at the University of Wisconsin-Madison, where his research focuses on signal processing, machine learning, optimization, and statistics._ 

>**Dataset Curation via Active Learning** The field of Machine Learning (ML) has advanced considerably in recent years, but mostly in well-defined domains using huge amounts of human-labeled training data. Machines can recognize objects in images and translate text, but they must be trained with more images and text than a person can see in nearly a lifetime.  The computational complexity of training has been offset by recent technological advances, but the cost of training data is measured in terms of the human effort in labeling data. People are not getting faster nor cheaper, so generating labeled training datasets has become a major bottleneck in ML pipelines. 
> 
>Active ML aims to address this issue by designing learning algorithms that automatically and adaptively select the most informative examples for labeling so that human time is not wasted labeling irrelevant, redundant, or trivial examples. This talk explores the development of active ML theory and methods over the past decade, including a new approach applicable to kernel methods and neural networks, which views the learning problem through the lens of representer theorems. This perspective highlights the effect that adding a given training example has on the representation.   The new approach is shown to possess a variety of desirable mathematical properties that allow active learning algorithms to learn good classifiers from few labeled examples.

**[Yejin Choi](https://homes.cs.washington.edu/~yejin/),** _University of Washington_.

## Call For Papers <a name="cfp"></a>
We are accepting submissions no longer than _four pages (plus references)_, in [NeurIPS 2020 format](https://neurips.cc/Conferences/2020/PaperInformation/StyleFiles). We ask that submissions are anonymized as the review process is _double blind_. <!-- We will not accept work that has been previously included in conference proceedings. -->

The submission deadline is Sunday October 11th, 2020 anywhere on Earth. Submission link: [Not yet set up.](https://youtu.be/eo5Wr0Ndd68?t=42)

## Organizers
**Nathalie Baracaldo,** _IBM_. leads the AI Security and Privacy Solutions team and is a Research Staff Member at IBM’s Almaden Research Center in San Jose, CA. Nathalie is focused on designing machine learning solutions that are accurate while withstanding adversarial attacks and protecting data privacy.

**Yonatan Bisk,** _Carnegie Mellon University_. is an Assistant Professor of Computer Science at Carnegie Mellon University in Language Technologies Institute. His work focuses on grounded and multimodal language representations and publishes regularly across the language, computer vision, robotics and machine learning community.

**Avrim Blum,** _TTIC_. is Professor and Chief Academic Officer at the Toyota Technological Institute at Chicago (TTIC); prior to this he was on the faculty at Carnegie Mellon University for 25 years.  His main research interests are in Machine Learning Theory, Algorithmic Game Theory, Privacy, and Algorithmic Fairness.

**Michael J. Curry,** _University of Maryland_. is a PhD student in the Computer Science department at the University of Maryland. He is co-advised by John Dickerson and Tom Goldstein on research in resource allocation, mechanism design, and adversarial robustness.

**John P. Dickerson,** _University of Maryland_. is an Assistant Professor of Computer Science at the University of Maryland and co-founder and Chief Scientist of Arthur AI, an enterprise-focused AI/ML model monitoring company.

**Micah Goldblum,** _University of Maryland_.  is a postdoctoral researcher, advised by Tom Goldstein, in computer science at the University of Maryland.  He works on security in AI as well as ML in the data-scarce regime. 

**Tom Goldstein,** _University of Maryland_. is the Perotto Associate Professor of Machine Learning in the Department of Computer Science at University of Maryland. His research lies at the intersection of machine learning and optimization, and focuses on safety and security for autonomous systems.

**Bo Li,** _University of Illinois at Urbana-Champaign_. is an assistant professor in Computer Science at the University of Illinois at Urbana-Champaign. Her research focuses on machine learning, security, privacy, game theory, social networks, and adversarial deep learning. She has designed several robust learning algorithms, scalable frameworks for achieving robustness for a range of learning methods, and privacy preserving data publishing systems.

**Avi Schwarzschild,** _University of Maryland_. Avi is a PhD student in the Applied Math and Scientific Computation program at the University of Maryland. He is advised by Tom Goldstein on his work in AI security, relating to data security and model vulnerability.

<!-- ## Program Committee
To be determined... -->

<!-- ## Workshop Schedule -->

<!-- ### Day One  -->

<!-- | Time    	| Speaker   	| Title            	|
|---------	|-----------	|------------------	|
| 9:00 am 	| Dawn Song 	| Dataset Security 	|
|         	|           	|                  	|
|         	|           	|                  	| -->

