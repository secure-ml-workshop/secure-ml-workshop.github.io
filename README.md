# Workshop on Dataset Curation and Security - NeurIPS 2020

Classical machine learning research has been focused largely on models,  optimizers,  and computational challenges. As technical progress and hardware advancements ease these challenges, practitioners are now finding that the limitations and faults of their models are the result of their datasets. This is particularly true of deep networks, which often rely on huge datasets that are too large and unwieldy for domain experts to curate by hand. We invite those interested to contribute in the discussion around dataset curation and security.

We have identified four areas of interest: Dataset security, policy and privacy, Dataset bias, and data scraping and labeling. In addition to the invited speakers listed below, we are excited to invite paper submissions on the topics of data poisoning and backdoor attacks, data sanitization, dataset bias, and dataset privacy. See the [call for papers](#cfp) below for more details.

## Invited Speakers
**Dawn Song,** _UC Berkeley_. (insert bio + abstract)

**Darrell M. West,** _Brookings Institution_. (insert bio + abstract)

**Yejin Choi,**, _University of Washington_. (bio here) 

**Rob Nowak,** _University of Wisconsin_. (insert bio + abstract)

## Call For Papers <a name="cfp"></a>
We are accepting submissions no longer than _four pages (plus references)_, in [NeurIPS 2020 format](https://neurips.cc/Conferences/2020/PaperInformation/StyleFiles). We ask that submission are anonymized as the review process is _double blind_. We will not accept work that has been previously included in conference proceedings.

Submission link: [Not yet set up.](https://youtu.be/eo5Wr0Ndd68?t=42)

## Organizers
**Nathalie Baracaldo,** _IBM_. leads the AI Security and Privacy Solutions team and is a Research Staff Member at IBM’s Almaden Research Center in San Jose, CA. Nathalie is focuses on designing machine learning solutions that are accurate while withstanding adversarial attacks and protect data privacy. Her team focuses on two main areas: federated learning, where models are trained without directly accessing training data and adversarial machine learning, where defenses are designed to withstand potential attacks to the machine learning pipeline.  Nathalie received her Ph.D. degree from the University of Pittsburgh in 2016. Her dissertation focused on preventing insider threats through the use of adaptive access control systems that integrate multiple sources of contextual information. Some of the topics that she has explored in the past include secure storage systems, privacy in online social networks, secure interoperability in distributed systems, risk management and trust evaluation.

**Yonatan Bisk,** _Carnegie Mellon University_. is an Assistant Professor of Computer Science at Carnegie Mellon University in Language Technologies Institute. His work focuses on grounded and multimodal language representations and publishes regularly across the language, computer vision, robotics and machine learning community, including relevant work involving large scale data collection and model robustness. He has also co-organized successful workshops at ACL (2017), NAACL (2018, 2019), NeurIPS (2018), and ECCV (2020).

**Avrim Blum,** _TTIC_. is Professor and Chief Academic Officer at the Toyota Technological Institute at Chicago (TTIC); prior to this he was on the faculty at Carnegie Mellon University for 25 years.  His main research interests are in Machine Learning Theory, Algorithmic Game Theory, Privacy, and Algorithmic Fairness.  Some current specific interests include multi-agent and distributed learning, learning systems that know when they don't know, and relations among fairness, accuracy, and incentives. He has served as Program Chair for the Conference on Learning Theory (COLT), the IEEE Symposium on Foundations of Computer Science (FOCS), and the Innovations in Theoretical Computer Science Conference (ITCS). He has served as Chair of the ACM SIGACT Committee for the Advancement of Theoretical Computer Science and on the SIGACT Executive Committee.  Blum is recipient of the AI Journal Classic Paper Award, the ICML/COLT 10-Year Best Paper Award, the Sloan Fellowship, the NSF National Young Investigator Award, and the Herbert Simon Teaching Award, and he is a Fellow of the ACM.

**Michael J. Curry,** _University of Maryland_. is a PhD student in the Computer Science department at the University of Maryland. He is co-advised by John Dickerson and Tom Goldstein on research in resource allocation, mechanism design, and adversarial robustness.

**John P. Dickerson,** _University of Maryland_. is an Assistant Professor of Computer Science at the University of Maryland and co-founder and Chief Scientist of Arthur AI, an enterprise-focused AI/ML model monitoring company.  He is recent recipient of awards such as the NSF CAREER Award, Google Faculty Research Award, and paper awards and nominations at venues such as AAAI.  His research centers on solving practical economic problems using techniques from computer science, stochastic optimization, and machine learning. He has worked extensively on theoretical and empirical approaches to kidney exchange where his work has set policy at the UNOS nationwide exchange; worldwide blood donation markets with Facebook; game-theoretic approaches to counter-terrorism and negotiation, where his models have been deployed; and market design problems in industry (e.g., online advertising) through various startups.

**Micah Goldblum,** _University of Maryland_.  is a postdoctoral researcher, advised by Tom Goldstein, in computer science at the University of Maryland.  He works on security in AI as well as AI in the data-scarce regime.  He has designed several methods for securing ML systems from adversarial threats, and he has worked on exposing security risks in algorithmic trading systems.  He is the recipient of the Seymour Goldberg Gold Medal in Graduate Student Research.

<img src="tom_headshot_small.jpg" width="200"> **Tom Goldstein,** _University of Maryland_. is the Perotto Associate Professor of Machine Learning in the Department of Computer Science at University of Maryland. His research lies at the intersection of machine learning and optimization, and focuses on safety and security for autonomous systems. He works at the boundary between theory and practice, leveraging mathematical foundations, complex models, and efficient hardware to build practical, high-performance systems. He designs optimization methods for a wide range of platforms ranging from powerful cluster/cloud computing environments to resource limited integrated circuits and FPGAs. Before joining the faculty at Maryland, he completed his PhD in Mathematics at UCLA, and was a research scientist at Rice University and Stanford University. He has been the recipient of several awards, including SIAM’s DiPrima Prize, the DARPA Young Faculty Award, the JP Morgan Faculty Fellowship, and the Sloan Fellowship.  Tom has been a co-organizer of several workshops, and was the lead organizer of a AAAI workshop on distributed computation in 2016, and the lead organizer of an ARO sponsored workshop on domain shift in vision applications in 2020.   He served as a conference AC for NeuRIPS in 2018, 2019, and is currently serving for 2020.  He was also a conference AC at ICML in 2018 and 2019.

**Bo Li,** _University of Illinois at Urbana-Champaign_. is an assistant professor in Computer Science at the University of Illinois at Urbana-Champaign. She is the recipient of several awards including the Symantec Research Labs Fellowship, the MIT Technology Review TR-35 Award, and Best Paper Awards of top machine learning and security conferences. Her research focuses on machine learning, security, privacy, game theory, social networks, and adversarial deep learning. She has designed several robust learning algorithms, scalable frameworks for achieving robustness for a range of learning methods, and privacy preserving data publishing systems. She is interested in both theoretical analysis of general machine learning models and developing practical systems. 


**Avi Schwarzschild,** _University of Maryland_. Avi is a PhD student in the Applied Math and Scientific Computation program at the University of Maryland. He is advised by Tom Goldstein on his work in AI security, relating to data security and model vulnerability.


## Program Committee
To be determined...

## Workshop Schedule
### Day One 

| Time    	| Speaker   	| Title            	|
|---------	|-----------	|------------------	|
| 9:00 am 	| Dawn Song 	| Dataset Security 	|
|         	|           	|                  	|
|         	|           	|                  	|

### Day Two 

| Time    	| Speaker   	    | Title            	|
|---------	|---------------	|------------------	|
| 9:00 am 	| Darrell M. West	| Policy + Privacy	|
|         	|           	    |                  	|
|         	|           	    |                  	|
